# -*- coding: utf-8 -*-
"""Copy of RAFT_Stereo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y3vcrT72F7JBBAyyffIBaGp7Wv_nnviH

This Google Colab demos our method

# RAFT-Stereo

```
@inproceedings{lipson2021raft,
  title={RAFT-Stereo: Multilevel Recurrent Field Transforms for Stereo Matching},
  author={Lipson, Lahav and Teed, Zachary and Deng, Jia},
  booktitle={International Conference on 3D Vision (3DV)},
  year={2021}
}
```

Github Repo: https://github.com/princeton-vl/RAFT-Stereo

Paper: https://arxiv.org/pdf/2109.07547.pdf

## Steps

1)   Build the Conda Environment [~9 min] (**This will restart the runtime. To run steps 2-5, select the next cell and from the dropdown menu select `Runtime -> Run after`**)

2)   Download sample data

3)   Run RAFT-Stereo

4)   Create Point Cloud From Predicted Disparity

5)   Visualize 3D Point Cloud

## 1) Build the Conda Environment [~9 min]
"""





print("\nThe runtime has restarted. To run steps 2-5, select the next cell and from the dropdown select Runtime -> Run after")

"""## 2) Download sample data [~1 min]

### **To run steps 2-5, select this cell and from the dropdown menu select `Runtime -> Run after**`
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/RAFT-Stereo
 # for visualization

# Download model weights and sample data
# bash download_datasets.sh
# bash download_models.sh

"""## 3) Run RAFT-Stereo

### You can replace the images and calibration with your own
"""

# !source activate raftstereo && python demo.py --restore_ckpt models/raftstereo-middlebury.pth \
# --corr_implementation alt --mixed_precision \
# -l=datasets/Middlebury/MiddEval3/testF/Bicycle2/im0.png \
# -r=datasets/Middlebury/MiddEval3/testF/Bicycle2/im1.png \
# --save_numpy

# Calibration
# fx, fy, cx1, cy = (1429.4995220185822 + 1433.6695087748499)/2.0, (1430.4111785502332 + 1434.7285140471024)/2.0, 929.8227256572083, (506.4722541384677 + 520.1168815891416)/2.0
fx, fy, cx1, cy = 1429.4995220185822, 1430.4111785502332, 929.8227256572083, 506.4722541384677

cx2 = 936.8035788332203
baseline = 32.95550620237698 # in millimeters



"""## 4) Create Point Cloud From Predicted Disparity


"""

import plotly.graph_objects as go
import numpy as np
from pathlib import Path
import cv2 as cv
import os
import open3d as o3d
# Define la ruta del directorio testF
#testF_folder = Path("datasets/Middlebury/MiddEval3/testF/Bicycle2")
testF_folder = Path("datasets/CIDIS/Laser_ground_truth/790")
# Define la ruta del archivo de disparidad y la imagen
disp_path = Path(f"demo_output/{testF_folder.name}.npy")
image_path = testF_folder / "15_30_41_07_06_2024_IMG_LEFT.jpg"

# Verifica si el archivo de disparidad existe antes de cargarlo
if disp_path.exists():
    disp = np.load(disp_path)
else:
    print(f"El archivo {disp_path} no existe.")
    # Maneja el error según sea necesario, por ejemplo, saliendo del script
    exit(1)

# Verifica si la imagen existe antes de cargarla
if image_path.exists():
    image = cv.imread(str(image_path), cv.IMREAD_COLOR)
    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)
else:
    print(f"La imagen {image_path} no existe.")
    # Maneja el error según sea necesario, por ejemplo, saliendo del script
    exit(1)

# inverse-project
depth = (fx * baseline) / (-disp + (cx2 - cx1))
H, W = depth.shape
xx, yy = np.meshgrid(np.arange(W), np.arange(H), indexing='ij')
points_grid = np.stack(((xx-cx1)/fx, (yy-cy)/fy, np.ones_like(xx)), axis=0) * depth

# mask = np.ones((H, W), dtype=bool)

# # Remove flying points
# mask[1:][np.abs(depth[1:] - depth[:-1]) > 1] = True
# mask[:,1:][np.abs(depth[:,1:] - depth[:,:-1]) > 1] = True

points = points_grid.transpose(1, 2, 0).reshape(-1, 3)
colors = image.reshape(-1, 3).astype(np.float64) / 255

"""## 5) Visualize 3D Point Cloud

"""
print(points.shape)
# NUM_POINTS_TO_DRAW = 2073600

# subset = np.random.choice(points.shape[0], size=(NUM_POINTS_TO_DRAW,), replace=False)
# points_subset = points[subset]
# colors_subset = colors[subset]
origin = o3d.geometry.TriangleMesh.create_coordinate_frame(size=10, origin=[0,0,0])
print("""
Controls:
---------
Zoom:      Scroll Wheel
Translate: Right-Click + Drag
Rotate:    Left-Click + Drag
""")

# OPEN3D
# pcd = o3d.geometry.PointCloud()
# pcd.points = o3d.utility.Vector3dVector(points)
# pcd.colors = o3d.utility.Vector3dVector(colors)

# # Visualizar la nube de puntos
# o3d.visualization.draw_geometries([pcd, origin], window_name="Nube de Puntos 3D", width=800, height=600)



# MATPLOTLIB
# Seleccionar un subconjunto aleatorio de puntos


print("""
Controls:
---------
Zoom:      Scroll Wheel
Translate: Right-Click + Drag
Rotate:    Left-Click + Drag
""")



# Añadir el origen (0,0,0) con un color distintivo (rojo)
origin_point = np.array([[0, 0, 0]])
origin_color = np.array([[1, 0, 0]])  # Color rojo

# Combinar el origen con los puntos y colores existentes
points = np.vstack([points, origin_point])
colors = np.vstack([colors, origin_color])

# Seleccionar un subconjunto aleatorio de puntos, incluyendo el origen
NUM_POINTS_TO_DRAW = 250000
subset = np.random.choice(points.shape[0], size=(NUM_POINTS_TO_DRAW - 1,), replace=False)
subset = np.append(subset, points.shape[0] - 1)  # Asegurar que el origen esté incluido
points_subset = points[subset]
colors_subset = colors[subset]



x, y, z = points_subset.T

fig = go.Figure(
    data=[
        go.Scatter3d(
            x=x, y=y, z=z, # flipped to make visualization nicer
            mode='markers',
            marker=dict(size=1, color=colors_subset)
        )
    ],
    layout=dict(
        scene=dict(
            xaxis=dict(visible=True),
            yaxis=dict(visible=True),
            zaxis=dict(visible=True),
        )
    )
)
fig.show()